
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Pull Hive -> load to Oracle -> write CSV to shared network.
Table: ENCR.EWRA_ASCENTIUM
Columns (from your query):
  unq_id_in_src_sys (STRING)
  contractnum       (STRING)
  amountapplied     (DECIMAL/DOUBLE)
  paymenttype       (STRING)
  postdate          (DATE)
"""

import argparse
import datetime as dt
import getpass
import logging
import os
from pathlib import Path

import pandas as pd

# Hive
from pyhive import hive

# Oracle (thin mode; works without Oracle Client)
import oracledb

# --------------- Configuration ----------------
# Prefer environment variables for secrets. You can also use a .env file.
HIVE_HOST = os.getenv("HIVE_HOST", "your-hive-host")
HIVE_PORT = int(os.getenv("HIVE_PORT", 10000))
HIVE_USERNAME = os.getenv("HIVE_USER", getpass.getuser())
HIVE_AUTH = os.getenv("HIVE_AUTH", "NONE")  # NONE | LDAP | KERBEROS
HIVE_DATABASE = os.getenv("HIVE_DATABASE", "default")

# Oracle EZCONNECT, e.g. "host:1521/service_name" or TCPS string.
ORACLE_DSN = os.getenv("ORACLE_DSN", "your-oracle-host:1521/ENCRPDB")
ORACLE_USER = os.getenv("ORACLE_USER", "ENCR_APP")
ORACLE_PASS = os.getenv("ORACLE_PASS", "*****")

# Target Oracle schema/table
ORACLE_SCHEMA = os.getenv("ORACLE_SCHEMA", "ENCR")
ORACLE_TABLE = os.getenv("ORACLE_TABLE", "EWRA_ASCENTIUM")

# Chunk sizes
HIVE_FETCH_SIZE = int(os.getenv("HIVE_FETCH_SIZE", "50000"))
ORACLE_BATCH_SIZE = int(os.getenv("ORACLE_BATCH_SIZE", "1000"))

# --------------- Logging ----------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s"
)
log = logging.getLogger("hive_to_oracle")

# --------------- SQL ----------------
CREATE_TABLE_SQL = f"""
DECLARE
  v_count INTEGER;
BEGIN
  SELECT COUNT(*) INTO v_count
  FROM all_tables
  WHERE owner = UPPER('{ORACLE_SCHEMA}')
    AND table_name = UPPER('{ORACLE_TABLE}');
  IF v_count = 0 THEN
    EXECUTE IMMEDIATE '
      CREATE TABLE {ORACLE_SCHEMA}.{ORACLE_TABLE} (
        UNQ_ID_IN_SRC_SYS VARCHAR2(128),
        CONTRACTNUM       VARCHAR2(64),
        AMOUNTAPPLIED     NUMBER(18,4),
        PAYMENTTYPE       VARCHAR2(64),
        POSTDATE          DATE
      )';
  END IF;
END;
"""

TRUNCATE_SQL = f"TRUNCATE TABLE {ORACLE_SCHEMA}.{ORACLE_TABLE}"

INSERT_SQL = f"""
INSERT INTO {ORACLE_SCHEMA}.{ORACLE_TABLE}
  (UNQ_ID_IN_SRC_SYS, CONTRACTNUM, AMOUNTAPPLIED, PAYMENTTYPE, POSTDATE)
VALUES
  (:1, :2, :3, :4, :5)
"""

HIVE_QUERY_TEMPLATE = """
SELECT DISTINCT
  unq_id_in_src_sys,
  contractnum,
  amountapplied,
  paymenttype,
  postdate
FROM payment_h
WHERE postdate BETWEEN DATE '{start}' AND DATE '{end}'
"""

# --------------- Helpers ----------------
def hive_connect():
    kwargs = dict(host=HIVE_HOST, port=HIVE_PORT, username=HIVE_USERNAME, database=HIVE_DATABASE)
    if HIVE_AUTH.upper() == "LDAP":
        kwargs["auth"] = "LDAP"
        kwargs["password"] = os.getenv("HIVE_PASSWORD") or getpass.getpass("Hive LDAP password: ")
    elif HIVE_AUTH.upper() == "KERBEROS":
        kwargs["auth"] = "KERBEROS"
    else:
        kwargs["auth"] = "NONE"
    return hive.Connection(**kwargs)

def oracle_connect():
    # Thin mode by default
    return oracledb.connect(user=ORACLE_USER, password=ORACLE_PASS, dsn=ORACLE_DSN)

def ensure_table(conn):
    log.info("Ensuring target table exists...")
    with conn.cursor() as cur:
        cur.execute(CREATE_TABLE_SQL)
    conn.commit()

def truncate_table(conn):
    log.info("Truncating target table...")
    with conn.cursor() as cur:
        cur.execute(TRUNCATE_SQL)
    conn.commit()

def write_csv(df: pd.DataFrame, out_dir: Path, start: str, end: str) -> Path:
    out_dir.mkdir(parents=True, exist_ok=True)
    ts = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    out_path = out_dir / f"EWRA_Ascentium_{start}_to_{end}_{ts}.csv"
    df.to_csv(out_path, index=False)
    log.info("CSV written: %s", out_path)
    return out_path

def rows_generator(cursor, fetch_size):
    while True:
        rows = cursor.fetchmany(fetch_size)
        if not rows:
            break
        for r in rows:
            yield r

# --------------- Main ----------------
def main():
    parser = argparse.ArgumentParser(description="Hive -> Oracle -> CSV")
    parser.add_argument("--start", required=True, help="Start date (YYYY-MM-DD)")
    parser.add_argument("--end", required=True, help="End date (YYYY-MM-DD)")
    parser.add_argument("--csv-dir", required=True, help=r"Output dir (e.g. \\server\share\ENCR\EWRA)")
    parser.add_argument("--append", action="store_true", help="Append to Oracle table (skip truncate)")
    args = parser.parse_args()

    # Validate dates
    start_date = dt.datetime.strptime(args.start, "%Y-%m-%d").date()
    end_date = dt.datetime.strptime(args.end, "%Y-%m-%d").date()
    if end_date < start_date:
        raise ValueError("end date must be >= start date")

    hive_sql = HIVE_QUERY_TEMPLATE.format(start=start_date.isoformat(), end=end_date.isoformat())
    log.info("Hive SQL:\n%s", hive_sql)

    # Connect to Hive
    log.info("Connecting to Hive %s:%s database=%s auth=%s", HIVE_HOST, HIVE_PORT, HIVE_DATABASE, HIVE_AUTH)
    hconn = hive_connect()
    hcur = hconn.cursor()
    hcur.execute(hive_sql)

    # Connect to Oracle
    log.info("Connecting to Oracle DSN=%s user=%s", ORACLE_DSN, ORACLE_USER)
    oconn = oracle_connect()
    ensure_table(oconn)
    if not args.append:
        truncate_table(oconn)

    total = 0
    batch = []
    with oconn.cursor() as ocur:
        for row in rows_generator(hcur, HIVE_FETCH_SIZE):
            # Convert to Oracle-friendly types
            unq_id_in_src_sys, contractnum, amountapplied, paymenttype, postdate = row

            # Coercions
            amountapplied = None if amountapplied is None else float(amountapplied)
            # Hive may return date/datetime as string; normalize to date
            if isinstance(postdate, str):
                postdate = pd.to_datetime(postdate).date()
            elif isinstance(postdate, dt.datetime):
                postdate = postdate.date()

            batch.append((
                unq_id_in_src_sys,
                contractnum,
                amountapplied,
                paymenttype,
                postdate
            ))

            if len(batch) >= ORACLE_BATCH_SIZE:
                ocur.executemany(INSERT_SQL, batch)
                oconn.commit()
                total += len(batch)
                log.info("Inserted %d rows (running total=%d)...", len(batch), total)
                batch.clear()

        # flush remaining
        if batch:
            ocur.executemany(INSERT_SQL, batch)
            oconn.commit()
            total += len(batch)
            log.info("Inserted %d rows (running total=%d)...", len(batch), total)

    log.info("Finalizing CSV export from Oracle rows just loaded...")
    # Pull the rows we loaded (for the same range) and write a CSV to the share
    query_for_csv = f"""
        SELECT UNQ_ID_IN_SRC_SYS, CONTRACTNUM, AMOUNTAPPLIED, PAYMENTTYPE, POSTDATE
        FROM {ORACLE_SCHEMA}.{ORACLE_TABLE}
        WHERE POSTDATE BETWEEN DATE :1 AND DATE :2
        ORDER BY POSTDATE
    """
    df = pd.read_sql(query_for_csv, oconn, params=[start_date, end_date])
    csv_path = write_csv(df, Path(args.csv_dir), start_date.isoformat(), end_date.isoformat())

    # Cleanup
    hcur.close()
    hconn.close()
    oconn.close()
    log.info("Done. Rows loaded: %d. CSV: %s", len(df), csv_path)

if __name__ == "__main__":
    main()
